{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, \\\n",
    "    roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends = pd.read_csv('processed/friends.csv')\n",
    "links_train = pd.read_csv('processed/links_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends = pd.read_csv('processed/friends.csv')\n",
    "links_train = pd.read_csv('processed/links_train.csv')\n",
    "\n",
    "filtered_data = links_train[links_train['is_friends'] == 1]\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "G.add_edges_from(filtered_data[['user1', 'user2']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "G.add_edges_from(filtered_data[['user1', 'user2']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_neighbors(user1, user2):\n",
    "    try:\n",
    "        return len(list(nx.common_neighbors(G, user1, user2)))\n",
    "    except nx.NetworkXError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def resource_allocation_index(user1, user2):\n",
    "    try:\n",
    "        preds = next(nx.resource_allocation_index(G, [(user1, user2)]))\n",
    "        u, v, p = preds\n",
    "        return p\n",
    "    except nx.NetworkXError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def jaccard_coefficient(user1, user2):\n",
    "    try:\n",
    "        preds = next(nx.jaccard_coefficient(G, [(user1, user2)]))\n",
    "        u, v, p = preds\n",
    "        return p\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def adamic_adar_index(user1, user2):\n",
    "    try:\n",
    "        preds = next(nx.adamic_adar_index(G, [(user1, user2)]))\n",
    "        u, v, p = preds\n",
    "        return p\n",
    "    except nx.NetworkXError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def preferential_attachment(user1, user2):\n",
    "    try:\n",
    "        preds = next(nx.preferential_attachment(G, [(user1, user2)]))\n",
    "        u, v, p = preds\n",
    "        return p\n",
    "    except nx.NetworkXError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def has_path(user1, user2):\n",
    "    return (user1 in G) and (user2 in G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv('processed/profiles.csv')\n",
    "posts = pd.read_csv('processed/posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "\n",
    "def parse_list_string(list_string):\n",
    "    try:\n",
    "        return ast.literal_eval(list_string)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "profiles_clean = pd.DataFrame()\n",
    "\n",
    "cols = ['schools', 'universities', 'faculties']\n",
    "\n",
    "profiles_clean['id'] = profiles['id']\n",
    "profiles_clean['city'] = profiles['city']\n",
    "profiles_clean['sex'] = profiles['sex']\n",
    "\n",
    "for col in cols:\n",
    "    profiles_clean[col] = profiles[col].apply(parse_list_string)\n",
    "    profiles_clean[col] = profiles_clean[col].map(lambda arr: list(filter(lambda el: el is not None, arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_clean = profiles_clean.fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = posts.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_elements(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    return len(set1.intersection(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sex_relation(sex1, sex2):\n",
    "    if sex1 == 1 and sex2 == 1:\n",
    "        return 0\n",
    "    elif sex1 == 1 and sex2 == 2:\n",
    "        return 1\n",
    "    elif sex1 == 2 and sex2 == 1:\n",
    "        return 2\n",
    "    elif sex1 == 2 and sex2 == 2:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_train_features = links_train.copy()\n",
    "\n",
    "links_train_features = links_train_features.merge(profiles_clean, left_on='user1', right_on='id', how='left')\n",
    "links_train_features = links_train_features.merge(profiles_clean, left_on='user2', right_on='id', suffixes=('_user1', '_user2'), how='left')\n",
    "\n",
    "links_train_features['shared_schools'] = links_train_features.parallel_apply(lambda row: shared_elements(row['schools_user1'], row['schools_user2']), axis=1)\n",
    "links_train_features['shared_universities'] = links_train_features.parallel_apply(lambda row: shared_elements(row['universities_user1'], row['universities_user2']), axis=1)\n",
    "links_train_features['shared_faculties'] = links_train_features.parallel_apply(lambda row: shared_elements(row['faculties_user1'], row['faculties_user2']), axis=1)\n",
    "links_train_features['same_sex'] = links_train_features.parallel_apply(lambda row: sex_relation(row['sex_user1'], row['sex_user2']), axis=1).astype(int)\n",
    "links_train_features['same_city'] = (links_train_features['city_user1'] == links_train_features['city_user2']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['user1', 'user2', 'shared_schools', 'shared_universities', 'shared_faculties', 'same_city', 'same_sex']\n",
    "\n",
    "links_train_features = links_train_features[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(user_pair):\n",
    "    u1, u2 = user_pair\n",
    "    return (\n",
    "        u1,\n",
    "        u2,\n",
    "        common_neighbors(u1, u2),\n",
    "        resource_allocation_index(u1, u2),\n",
    "        jaccard_coefficient(u1, u2),\n",
    "        adamic_adar_index(u1, u2),\n",
    "        preferential_attachment(u1, u2),\n",
    "        has_path(u1, u2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "users = sorted(set(friends.user1.tolist()))\n",
    "user_pairs = [(u1, u2) for i, u1 in enumerate(users) for j, u2 in enumerate(users) if j > i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool(mp.cpu_count() // 2) as pool:\n",
    "    results = list(\n",
    "        tqdm(\n",
    "            pool.imap_unordered(\n",
    "                calculate_similarity, \n",
    "                user_pairs, \n",
    "                chunksize=(len(user_pairs) // 50)\n",
    "            ), \n",
    "            total=len(user_pairs)\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Collect the results\n",
    "graph_features = pd.DataFrame(results, columns=['user1', 'user2', 'common_neighbors', 'resource_allocation', 'jaccard_coefficient', 'adamic_adar', 'preferential_attachment', 'has_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(graph_features, links_train_features,  how='inner', on=['user1','user2'])\n",
    "df = graph_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(links_train, df,  how='inner', on=['user1', 'user2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'is_friends'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=[target])\n",
    "y = train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=4,\n",
    "    learning_rate=0.001,\n",
    "    l2_leaf_reg=0.1,\n",
    "    task_type=\"GPU\",\n",
    "    devices=\"0\"\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, eval_set=(X_val, y_val), use_best_model=True, \n",
    "    plot=True, verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = model.predict_proba(X_train)\n",
    "gt_train = y_train\n",
    "\n",
    "preds_val = model.predict_proba(X_val)\n",
    "gt_val = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(gt_train, preds_train.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(gt_val, preds_val.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = dict(average='weighted')\n",
    "params = dict()\n",
    "\n",
    "print(f'prec train: {precision_score(gt_train, preds_train.argmax(axis=1), **params):.3f} valid: {precision_score(gt_val, preds_val.argmax(axis=1), **params):.3f}')\n",
    "print(f'recall train: {recall_score(gt_train, preds_train.argmax(axis=1), **params):.3f} valid: {recall_score(gt_val, preds_val.argmax(axis=1), **params):.3f}')\n",
    "print(f'f1 train: {f1_score(gt_train, preds_train.argmax(axis=1), **params):.3f} valid: {f1_score(gt_val, preds_val.argmax(axis=1), **params):.3f}')\n",
    "print(f'roc auc train: {roc_auc_score(gt_train, preds_train[:, 1], **params):.3f} valid: {roc_auc_score(gt_val, preds_val[:, 1], **params):.3f}')\n",
    "\n",
    "print(f'\\nbalanced acc train: {balanced_accuracy_score(gt_train, preds_train.argmax(axis=1)):.3f} valid: {balanced_accuracy_score(gt_val, preds_val.argmax(axis=1)):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, tr = roc_curve(y_train, preds_train[:, 1])\n",
    "_ = plt.plot(fpr, tpr)\n",
    "_ = plt.plot((0, 1), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, tr = roc_curve(y_val, preds_val[:, 1])\n",
    "_ = plt.plot(fpr, tpr)\n",
    "_ = plt.plot((0, 1), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_val, preds_val.argmax(axis=1))).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(y_train, preds_train.argmax(axis=1))).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X, y = X_val, y_val\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(model, border):\n",
    "    preds_train = model.predict(X_train)\n",
    "    preds_val = model.predict(X_val)\n",
    "\n",
    "    train_score = balanced_accuracy_score(y_train, preds_train)\n",
    "    val_score = balanced_accuracy_score(y_val, preds_val)\n",
    "    print(f'{border} {train_score} {val_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for border in np.arange(0.1, 1, 0.1):\n",
    "#     model.set_probability_threshold(border)\n",
    "#     print_stats(model, border)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_test = pd.read_csv('processed/links_test.csv')\n",
    "test = links_test.merge(df, on=['user1', 'user2'], how='inner')\n",
    "\n",
    "test_pred = model.predict_proba(test[features]).argmax(axis=1)\n",
    "print('friends percentage: ', sum(test_pred) / len(test_pred))\n",
    "print('friends count: ', sum(test_pred))\n",
    "test_pred = test[['user1', 'user2']].assign(is_friends=test_pred)\n",
    "test_pred.assign(ID=list(range(len(test_pred))))[['ID', 'is_friends']].to_csv('pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
